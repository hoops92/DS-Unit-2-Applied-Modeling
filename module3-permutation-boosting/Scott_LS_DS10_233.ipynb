{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scott_LS_DS10_233.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hoops92/DS-Unit-2-Applied-Modeling/blob/master/module3-permutation-boosting/Scott_LS_DS10_233.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nCc3XZEyG3XV"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 2, Sprint 3, Module 3*\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# Permutation & Boosting\n",
        "\n",
        "You will use your portfolio project dataset for all assignments this sprint.\n",
        "\n",
        "## Assignment\n",
        "\n",
        "Complete these tasks for your project, and document your work.\n",
        "\n",
        "- [ ] If you haven't completed assignment #1, please do so first.\n",
        "- [ ] Continue to clean and explore your data. Make exploratory visualizations.\n",
        "- [ ] Fit a model. Does it beat your baseline? \n",
        "- [ ] Try xgboost.\n",
        "- [ ] Get your model's permutation importances.\n",
        "\n",
        "You should try to complete an initial model today, because the rest of the week, we're making model interpretation visualizations.\n",
        "\n",
        "But, if you aren't ready to try xgboost and permutation importances with your dataset today, that's okay. You can practice with another dataset instead. You may choose any dataset you've worked with previously.\n",
        "\n",
        "The data subdirectory includes the Titanic dataset for classification and the NYC apartments dataset for regression. You may want to choose one of these datasets, because example solutions will be available for each.\n",
        "\n",
        "\n",
        "## Reading\n",
        "\n",
        "Top recommendations in _**bold italic:**_\n",
        "\n",
        "#### Permutation Importances\n",
        "- _**[Kaggle / Dan Becker: Machine Learning Explainability](https://www.kaggle.com/dansbecker/permutation-importance)**_\n",
        "- [Christoph Molnar: Interpretable Machine Learning](https://christophm.github.io/interpretable-ml-book/feature-importance.html)\n",
        "\n",
        "#### (Default) Feature Importances\n",
        "  - [Ando Saabas: Selecting good features, Part 3, Random Forests](https://blog.datadive.net/selecting-good-features-part-iii-random-forests/)\n",
        "  - [Terence Parr, et al: Beware Default Random Forest Importances](https://explained.ai/rf-importance/index.html)\n",
        "\n",
        "#### Gradient Boosting\n",
        "  - [A Gentle Introduction to the Gradient Boosting Algorithm for Machine Learning](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/)\n",
        "  - _**[A Kaggle Master Explains Gradient Boosting](http://blog.kaggle.com/2017/01/23/a-kaggle-master-explains-gradient-boosting/)**_\n",
        "  - [_An Introduction to Statistical Learning_](http://www-bcf.usc.edu/~gareth/ISL/ISLR%20Seventh%20Printing.pdf) Chapter 8\n",
        "  - [Gradient Boosting Explained](http://arogozhnikov.github.io/2016/06/24/gradient_boosting_explained.html)\n",
        "  - _**[Boosting](https://www.youtube.com/watch?v=GM3CDQfQ4sw) (2.5 minute video)**_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "txS3vQkTRsjC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "import sys\n",
        "\n",
        "!pip install category_encoders==2.*\n",
        "!pip install pandas-profiling==2.*"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qPIdscE1w3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/Okocha76/Okocha76.github.io/master/euro_data.csv', sep=';', engine='python', encoding = \"ISO-8859-1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9vV6W2Y-umB",
        "colab_type": "code",
        "outputId": "6d96838d-8b72-4571-8962-04cf346ca597",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        }
      },
      "source": [
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8010, 41)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TIME</th>\n",
              "      <th>GEO</th>\n",
              "      <th>GEO_LABEL</th>\n",
              "      <th>AGEMOTH</th>\n",
              "      <th>MEDAGEMOTH</th>\n",
              "      <th>TOTFERRT</th>\n",
              "      <th>JAN</th>\n",
              "      <th>CNMIGRAT</th>\n",
              "      <th>CNMIGRATRT</th>\n",
              "      <th>DEATH</th>\n",
              "      <th>GBIRTHRT</th>\n",
              "      <th>GDEATHRT</th>\n",
              "      <th>GROW</th>\n",
              "      <th>GROWRT</th>\n",
              "      <th>LBIRTH</th>\n",
              "      <th>NATGROW</th>\n",
              "      <th>NATGROWRT</th>\n",
              "      <th>RT</th>\n",
              "      <th>PER_KM2</th>\n",
              "      <th>EUR_HAB_2GDP</th>\n",
              "      <th>EUR_HAB_EU</th>\n",
              "      <th>EUR_HAB_EU27_2019</th>\n",
              "      <th>MIO_EUR</th>\n",
              "      <th>MIO_NAC</th>\n",
              "      <th>MIO_PPS</th>\n",
              "      <th>MIO_PPS_EU27_2019</th>\n",
              "      <th>PPS_EU27_2019_HAB</th>\n",
              "      <th>PPS_HAB</th>\n",
              "      <th>PPS_HAB_EU</th>\n",
              "      <th>PPS_HAB_EU27_2019</th>\n",
              "      <th>EMP</th>\n",
              "      <th>SAL</th>\n",
              "      <th>EUR_HAB_2HHINC</th>\n",
              "      <th>ED0-2_25_64</th>\n",
              "      <th>ED3_4_25_64</th>\n",
              "      <th>ED3-8_25_64</th>\n",
              "      <th>ED5-8_25_64</th>\n",
              "      <th>ED0-2_30_34</th>\n",
              "      <th>ED3_4_30_34</th>\n",
              "      <th>ED3-8_30_34</th>\n",
              "      <th>ED5-8_30_34</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>AT</td>\n",
              "      <td>Austria</td>\n",
              "      <td>28.7</td>\n",
              "      <td>29.4</td>\n",
              "      <td>1.35</td>\n",
              "      <td>8002186</td>\n",
              "      <td>17272</td>\n",
              "      <td>2.2</td>\n",
              "      <td>76780</td>\n",
              "      <td>9.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>18760</td>\n",
              "      <td>2.3</td>\n",
              "      <td>78268</td>\n",
              "      <td>1488</td>\n",
              "      <td>0.2</td>\n",
              "      <td>4.8</td>\n",
              "      <td>97.2</td>\n",
              "      <td>26700</td>\n",
              "      <td>134</td>\n",
              "      <td>145</td>\n",
              "      <td>213606.48</td>\n",
              "      <td>213606.48</td>\n",
              "      <td>206251.54</td>\n",
              "      <td>195513.50</td>\n",
              "      <td>24400</td>\n",
              "      <td>25700</td>\n",
              "      <td>130</td>\n",
              "      <td>133</td>\n",
              "      <td>3755.0</td>\n",
              "      <td>3243.7</td>\n",
              "      <td>18000</td>\n",
              "      <td>23.8</td>\n",
              "      <td>62.1</td>\n",
              "      <td>76.2</td>\n",
              "      <td>14.1</td>\n",
              "      <td>16.7</td>\n",
              "      <td>67.4</td>\n",
              "      <td>83.3</td>\n",
              "      <td>15.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>AT</td>\n",
              "      <td>Austria</td>\n",
              "      <td>28.9</td>\n",
              "      <td>29.6</td>\n",
              "      <td>1.31</td>\n",
              "      <td>8020946</td>\n",
              "      <td>42003</td>\n",
              "      <td>5.2</td>\n",
              "      <td>74767</td>\n",
              "      <td>9.4</td>\n",
              "      <td>9.3</td>\n",
              "      <td>42694</td>\n",
              "      <td>5.3</td>\n",
              "      <td>75458</td>\n",
              "      <td>691</td>\n",
              "      <td>0.1</td>\n",
              "      <td>4.8</td>\n",
              "      <td>97.5</td>\n",
              "      <td>27400</td>\n",
              "      <td>133</td>\n",
              "      <td>143</td>\n",
              "      <td>220525.08</td>\n",
              "      <td>220525.08</td>\n",
              "      <td>207461.48</td>\n",
              "      <td>197764.57</td>\n",
              "      <td>24600</td>\n",
              "      <td>25800</td>\n",
              "      <td>125</td>\n",
              "      <td>128</td>\n",
              "      <td>3782.0</td>\n",
              "      <td>3265.1</td>\n",
              "      <td>18300</td>\n",
              "      <td>22.5</td>\n",
              "      <td>62.6</td>\n",
              "      <td>77.5</td>\n",
              "      <td>14.8</td>\n",
              "      <td>16.0</td>\n",
              "      <td>67.9</td>\n",
              "      <td>84.0</td>\n",
              "      <td>16.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002</td>\n",
              "      <td>AT</td>\n",
              "      <td>Austria</td>\n",
              "      <td>29.1</td>\n",
              "      <td>29.8</td>\n",
              "      <td>1.38</td>\n",
              "      <td>8063640</td>\n",
              "      <td>34365</td>\n",
              "      <td>4.3</td>\n",
              "      <td>76131</td>\n",
              "      <td>9.7</td>\n",
              "      <td>9.4</td>\n",
              "      <td>36633</td>\n",
              "      <td>4.5</td>\n",
              "      <td>78399</td>\n",
              "      <td>2268</td>\n",
              "      <td>0.3</td>\n",
              "      <td>4.1</td>\n",
              "      <td>98.0</td>\n",
              "      <td>28100</td>\n",
              "      <td>132</td>\n",
              "      <td>141</td>\n",
              "      <td>226735.22</td>\n",
              "      <td>226735.22</td>\n",
              "      <td>216432.92</td>\n",
              "      <td>206562.16</td>\n",
              "      <td>25600</td>\n",
              "      <td>26800</td>\n",
              "      <td>126</td>\n",
              "      <td>129</td>\n",
              "      <td>3778.4</td>\n",
              "      <td>3258.1</td>\n",
              "      <td>18500</td>\n",
              "      <td>21.7</td>\n",
              "      <td>62.7</td>\n",
              "      <td>78.3</td>\n",
              "      <td>15.7</td>\n",
              "      <td>15.9</td>\n",
              "      <td>66.9</td>\n",
              "      <td>84.1</td>\n",
              "      <td>17.2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2003</td>\n",
              "      <td>AT</td>\n",
              "      <td>Austria</td>\n",
              "      <td>29.2</td>\n",
              "      <td>29.9</td>\n",
              "      <td>1.36</td>\n",
              "      <td>8100273</td>\n",
              "      <td>42565</td>\n",
              "      <td>5.2</td>\n",
              "      <td>77209</td>\n",
              "      <td>9.5</td>\n",
              "      <td>9.5</td>\n",
              "      <td>42300</td>\n",
              "      <td>5.2</td>\n",
              "      <td>76944</td>\n",
              "      <td>-265</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>98.5</td>\n",
              "      <td>28600</td>\n",
              "      <td>132</td>\n",
              "      <td>140</td>\n",
              "      <td>231862.46</td>\n",
              "      <td>231862.46</td>\n",
              "      <td>221219.87</td>\n",
              "      <td>214271.17</td>\n",
              "      <td>26400</td>\n",
              "      <td>27200</td>\n",
              "      <td>126</td>\n",
              "      <td>130</td>\n",
              "      <td>3803.0</td>\n",
              "      <td>3275.3</td>\n",
              "      <td>18900</td>\n",
              "      <td>21.0</td>\n",
              "      <td>63.3</td>\n",
              "      <td>79.0</td>\n",
              "      <td>15.7</td>\n",
              "      <td>14.3</td>\n",
              "      <td>68.1</td>\n",
              "      <td>85.7</td>\n",
              "      <td>17.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2004</td>\n",
              "      <td>AT</td>\n",
              "      <td>Austria</td>\n",
              "      <td>28.8</td>\n",
              "      <td>29.5</td>\n",
              "      <td>1.42</td>\n",
              "      <td>8142573</td>\n",
              "      <td>54110</td>\n",
              "      <td>6.6</td>\n",
              "      <td>74292</td>\n",
              "      <td>9.7</td>\n",
              "      <td>9.1</td>\n",
              "      <td>58786</td>\n",
              "      <td>7.2</td>\n",
              "      <td>78968</td>\n",
              "      <td>4676</td>\n",
              "      <td>0.6</td>\n",
              "      <td>4.5</td>\n",
              "      <td>99.1</td>\n",
              "      <td>29700</td>\n",
              "      <td>132</td>\n",
              "      <td>140</td>\n",
              "      <td>242348.26</td>\n",
              "      <td>242348.26</td>\n",
              "      <td>233343.6</td>\n",
              "      <td>225461.43</td>\n",
              "      <td>27600</td>\n",
              "      <td>28600</td>\n",
              "      <td>127</td>\n",
              "      <td>130</td>\n",
              "      <td>3826.8</td>\n",
              "      <td>3290.1</td>\n",
              "      <td>19700</td>\n",
              "      <td>20.2</td>\n",
              "      <td>61.8</td>\n",
              "      <td>79.8</td>\n",
              "      <td>18.0</td>\n",
              "      <td>13.5</td>\n",
              "      <td>65.6</td>\n",
              "      <td>86.5</td>\n",
              "      <td>20.9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TIME GEO GEO_LABEL  ...  ED3_4_30_34  ED3-8_30_34  ED5-8_30_34\n",
              "0  2000  AT   Austria  ...         67.4         83.3         15.9\n",
              "1  2001  AT   Austria  ...         67.9         84.0         16.1\n",
              "2  2002  AT   Austria  ...         66.9         84.1         17.2\n",
              "3  2003  AT   Austria  ...         68.1         85.7         17.6\n",
              "4  2004  AT   Austria  ...         65.6         86.5         20.9\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uaxerNAlcVP",
        "colab_type": "code",
        "outputId": "4398ce9c-ee76-440a-d348-d6579cf3b9ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train = df[df['TIME'] <= 2011]\n",
        "val = df[(df['TIME'] > 2011) & (df['TIME'] < 2015)]\n",
        "test = df[df['TIME'] >= 2015]\n",
        "\n",
        "train.shape, val.shape, test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((5340, 41), (1335, 41), (1335, 41))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYtAKbLUCap0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def wrangle(X):\n",
        "    \"\"\"Wrangle train, validate, and test sets in the same way\"\"\"\n",
        "    \n",
        "    # Prevent SettingWithCopyWarning\n",
        "    X = X.copy()\n",
        "\n",
        "    # Feature selection is not final. Just a quick & dirty approach for now.\n",
        "\n",
        "    X = X.drop(\n",
        "        ['CNMIGRAT','DEATH','GROW','GROWRT','LBIRTH','NATGROW','NATGROWRT',\n",
        "        'EUR_HAB_2GDP','EUR_HAB_EU27_2019','MIO_EUR','MIO_NAC','MIO_PPS',\n",
        "        'MIO_PPS_EU27_2019','PPS_EU27_2019_HAB','PPS_HAB','PPS_HAB_EU27_2019',\n",
        "        'SAL','EUR_HAB_2HHINC','ED0-2_25_64','ED3_4_25_64','ED3-8_25_64',\n",
        "        'ED5-8_25_64','ED3-8_30_34','MEDAGEMOTH','PPS_HAB_EU','ED3_4_30_34']\n",
        "        ,axis=1)\n",
        "    \n",
        "    X['JAN'] = pd.to_numeric(X['JAN'],errors='coerce')\n",
        "    # X['JAN'] = X['JAN'].astype(int)\n",
        "    X['TIME'] = X['TIME'].astype('category')\n",
        "\n",
        "    # A bit of feature engineering. EMP_PC is percentage employed.\n",
        "    X['EMP_PC'] = round((X['EMP'] * 100000)/X['JAN'],1)\n",
        "    X['EMP_PC'] = X['EMP_PC'].replace(np.inf, np.nan)\n",
        "    X = X.drop(['JAN','EMP'], axis=1)\n",
        "\n",
        "    # When columns have zeros and shouldn't, they are like null values.\n",
        "    # So we will replace the zeros with nulls, and impute missing values later.\n",
        "    cols_with_zeros = ['AGEMOTH', 'ED0-2_30_34', 'ED5-8_30_34','EMP_PC',\n",
        "                       'EUR_HAB_EU','GBIRTHRT','GDEATHRT','PER_KM2','RT',\n",
        "                       'TOTFERRT']\n",
        "\n",
        "    for col in cols_with_zeros:\n",
        "        X[col] = X[col].replace(0, np.nan)\n",
        "\n",
        "    X = X.rename(columns={\"ED0-2_30_34\": \"ED_LOW\", \"ED5-8_30_34\": \"ED_HIGH\"})    \n",
        "\n",
        "    # Make target feature categorical\n",
        "    X[\"MIG_CAT\"] = pd.cut(X[\"CNMIGRATRT\"], [-np.inf, 0, 5, np.inf], labels=[\"low\", \"avg\", \"high\"]).astype(np.object)\n",
        "    X = X.drop(['CNMIGRATRT'], axis=1)\n",
        "\n",
        "    # return the wrangled dataframe\n",
        "    return X\n",
        "\n",
        "\n",
        "train = wrangle(train)\n",
        "val = wrangle(val)\n",
        "test = wrangle(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPo0zB1YEG4M",
        "colab_type": "code",
        "outputId": "90e4821d-015c-40eb-972b-2536ecbc1611",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "print(train.shape)\n",
        "train.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5340, 14)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TIME</th>\n",
              "      <th>GEO</th>\n",
              "      <th>GEO_LABEL</th>\n",
              "      <th>AGEMOTH</th>\n",
              "      <th>TOTFERRT</th>\n",
              "      <th>GBIRTHRT</th>\n",
              "      <th>GDEATHRT</th>\n",
              "      <th>RT</th>\n",
              "      <th>PER_KM2</th>\n",
              "      <th>EUR_HAB_EU</th>\n",
              "      <th>ED_LOW</th>\n",
              "      <th>ED_HIGH</th>\n",
              "      <th>EMP_PC</th>\n",
              "      <th>MIG_CAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>AT</td>\n",
              "      <td>Austria</td>\n",
              "      <td>28.7</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.8</td>\n",
              "      <td>9.6</td>\n",
              "      <td>4.8</td>\n",
              "      <td>97.2</td>\n",
              "      <td>134.0</td>\n",
              "      <td>16.7</td>\n",
              "      <td>15.9</td>\n",
              "      <td>46.9</td>\n",
              "      <td>avg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>AT</td>\n",
              "      <td>Austria</td>\n",
              "      <td>28.9</td>\n",
              "      <td>1.31</td>\n",
              "      <td>9.4</td>\n",
              "      <td>9.3</td>\n",
              "      <td>4.8</td>\n",
              "      <td>97.5</td>\n",
              "      <td>133.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>16.1</td>\n",
              "      <td>47.2</td>\n",
              "      <td>high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2002</td>\n",
              "      <td>AT</td>\n",
              "      <td>Austria</td>\n",
              "      <td>29.1</td>\n",
              "      <td>1.38</td>\n",
              "      <td>9.7</td>\n",
              "      <td>9.4</td>\n",
              "      <td>4.1</td>\n",
              "      <td>98.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>15.9</td>\n",
              "      <td>17.2</td>\n",
              "      <td>46.9</td>\n",
              "      <td>avg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2003</td>\n",
              "      <td>AT</td>\n",
              "      <td>Austria</td>\n",
              "      <td>29.2</td>\n",
              "      <td>1.36</td>\n",
              "      <td>9.5</td>\n",
              "      <td>9.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>98.5</td>\n",
              "      <td>132.0</td>\n",
              "      <td>14.3</td>\n",
              "      <td>17.6</td>\n",
              "      <td>46.9</td>\n",
              "      <td>high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2004</td>\n",
              "      <td>AT</td>\n",
              "      <td>Austria</td>\n",
              "      <td>28.8</td>\n",
              "      <td>1.42</td>\n",
              "      <td>9.7</td>\n",
              "      <td>9.1</td>\n",
              "      <td>4.5</td>\n",
              "      <td>99.1</td>\n",
              "      <td>132.0</td>\n",
              "      <td>13.5</td>\n",
              "      <td>20.9</td>\n",
              "      <td>47.0</td>\n",
              "      <td>high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2005</td>\n",
              "      <td>AT</td>\n",
              "      <td>Austria</td>\n",
              "      <td>29.0</td>\n",
              "      <td>1.41</td>\n",
              "      <td>9.5</td>\n",
              "      <td>9.1</td>\n",
              "      <td>4.2</td>\n",
              "      <td>99.8</td>\n",
              "      <td>132.0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>20.7</td>\n",
              "      <td>47.2</td>\n",
              "      <td>high</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2006</td>\n",
              "      <td>AT</td>\n",
              "      <td>Austria</td>\n",
              "      <td>29.2</td>\n",
              "      <td>1.41</td>\n",
              "      <td>9.4</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>100.3</td>\n",
              "      <td>131.0</td>\n",
              "      <td>13.6</td>\n",
              "      <td>21.1</td>\n",
              "      <td>47.7</td>\n",
              "      <td>avg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2007</td>\n",
              "      <td>AT</td>\n",
              "      <td>Austria</td>\n",
              "      <td>29.4</td>\n",
              "      <td>1.38</td>\n",
              "      <td>9.2</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>100.6</td>\n",
              "      <td>131.0</td>\n",
              "      <td>13.5</td>\n",
              "      <td>20.9</td>\n",
              "      <td>48.4</td>\n",
              "      <td>avg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2008</td>\n",
              "      <td>AT</td>\n",
              "      <td>Austria</td>\n",
              "      <td>29.5</td>\n",
              "      <td>1.42</td>\n",
              "      <td>9.3</td>\n",
              "      <td>9.0</td>\n",
              "      <td>3.7</td>\n",
              "      <td>100.9</td>\n",
              "      <td>135.0</td>\n",
              "      <td>12.8</td>\n",
              "      <td>21.9</td>\n",
              "      <td>49.2</td>\n",
              "      <td>avg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2009</td>\n",
              "      <td>AT</td>\n",
              "      <td>Austria</td>\n",
              "      <td>29.7</td>\n",
              "      <td>1.39</td>\n",
              "      <td>9.2</td>\n",
              "      <td>9.3</td>\n",
              "      <td>3.8</td>\n",
              "      <td>101.2</td>\n",
              "      <td>141.0</td>\n",
              "      <td>11.7</td>\n",
              "      <td>23.4</td>\n",
              "      <td>48.8</td>\n",
              "      <td>avg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   TIME GEO GEO_LABEL  AGEMOTH  ...  ED_LOW  ED_HIGH  EMP_PC  MIG_CAT\n",
              "0  2000  AT   Austria     28.7  ...    16.7     15.9    46.9      avg\n",
              "1  2001  AT   Austria     28.9  ...    16.0     16.1    47.2     high\n",
              "2  2002  AT   Austria     29.1  ...    15.9     17.2    46.9      avg\n",
              "3  2003  AT   Austria     29.2  ...    14.3     17.6    46.9     high\n",
              "4  2004  AT   Austria     28.8  ...    13.5     20.9    47.0     high\n",
              "5  2005  AT   Austria     29.0  ...    13.9     20.7    47.2     high\n",
              "6  2006  AT   Austria     29.2  ...    13.6     21.1    47.7      avg\n",
              "7  2007  AT   Austria     29.4  ...    13.5     20.9    48.4      avg\n",
              "8  2008  AT   Austria     29.5  ...    12.8     21.9    49.2      avg\n",
              "9  2009  AT   Austria     29.7  ...    11.7     23.4    48.8      avg\n",
              "\n",
              "[10 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIhZcmRAUvbU",
        "colab_type": "code",
        "outputId": "1a59c7cb-dadf-4c8c-afe5-54f5d7286a60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "train.describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>AGEMOTH</th>\n",
              "      <th>TOTFERRT</th>\n",
              "      <th>GBIRTHRT</th>\n",
              "      <th>GDEATHRT</th>\n",
              "      <th>RT</th>\n",
              "      <th>PER_KM2</th>\n",
              "      <th>EUR_HAB_EU</th>\n",
              "      <th>ED_LOW</th>\n",
              "      <th>ED_HIGH</th>\n",
              "      <th>EMP_PC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4553.000000</td>\n",
              "      <td>4553.000000</td>\n",
              "      <td>4726.000000</td>\n",
              "      <td>4688.000000</td>\n",
              "      <td>4535.000000</td>\n",
              "      <td>5063.000000</td>\n",
              "      <td>4274.000000</td>\n",
              "      <td>4501.000000</td>\n",
              "      <td>4517.000000</td>\n",
              "      <td>3799.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>29.331496</td>\n",
              "      <td>1.582546</td>\n",
              "      <td>10.762992</td>\n",
              "      <td>9.887991</td>\n",
              "      <td>4.932172</td>\n",
              "      <td>382.158681</td>\n",
              "      <td>94.124474</td>\n",
              "      <td>25.558454</td>\n",
              "      <td>27.560040</td>\n",
              "      <td>45.534483</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.337198</td>\n",
              "      <td>0.325652</td>\n",
              "      <td>2.568682</td>\n",
              "      <td>1.922314</td>\n",
              "      <td>2.980237</td>\n",
              "      <td>978.579942</td>\n",
              "      <td>61.314426</td>\n",
              "      <td>16.774505</td>\n",
              "      <td>11.283108</td>\n",
              "      <td>8.912151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>24.300000</td>\n",
              "      <td>0.860000</td>\n",
              "      <td>6.400000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>1.400000</td>\n",
              "      <td>2.900000</td>\n",
              "      <td>27.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>28.700000</td>\n",
              "      <td>1.350000</td>\n",
              "      <td>9.200000</td>\n",
              "      <td>8.900000</td>\n",
              "      <td>3.300000</td>\n",
              "      <td>69.000000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>14.400000</td>\n",
              "      <td>19.000000</td>\n",
              "      <td>41.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>29.400000</td>\n",
              "      <td>1.520000</td>\n",
              "      <td>10.400000</td>\n",
              "      <td>9.800000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>112.800000</td>\n",
              "      <td>92.000000</td>\n",
              "      <td>20.400000</td>\n",
              "      <td>26.800000</td>\n",
              "      <td>45.200000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>30.200000</td>\n",
              "      <td>1.810000</td>\n",
              "      <td>11.800000</td>\n",
              "      <td>10.900000</td>\n",
              "      <td>5.300000</td>\n",
              "      <td>265.700000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>31.900000</td>\n",
              "      <td>35.700000</td>\n",
              "      <td>48.700000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>32.500000</td>\n",
              "      <td>3.940000</td>\n",
              "      <td>30.900000</td>\n",
              "      <td>19.800000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>10205.400000</td>\n",
              "      <td>716.000000</td>\n",
              "      <td>88.900000</td>\n",
              "      <td>77.500000</td>\n",
              "      <td>156.700000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           AGEMOTH     TOTFERRT  ...      ED_HIGH       EMP_PC\n",
              "count  4553.000000  4553.000000  ...  4517.000000  3799.000000\n",
              "mean     29.331496     1.582546  ...    27.560040    45.534483\n",
              "std       1.337198     0.325652  ...    11.283108     8.912151\n",
              "min      24.300000     0.860000  ...     2.900000    27.600000\n",
              "25%      28.700000     1.350000  ...    19.000000    41.000000\n",
              "50%      29.400000     1.520000  ...    26.800000    45.200000\n",
              "75%      30.200000     1.810000  ...    35.700000    48.700000\n",
              "max      32.500000     3.940000  ...    77.500000   156.700000\n",
              "\n",
              "[8 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW11JyIx2Dio",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate Pandas Profiling Report and export to html\n",
        "\n",
        "import pandas_profiling\n",
        "\n",
        "profile_report = train.profile_report(\n",
        "    check_correlation_pearson=True,\n",
        "    correlations={\n",
        "        'pearson': True,\n",
        "        'spearman': False,\n",
        "        'kendall': False,\n",
        "        'phi_k': False,\n",
        "        'cramers': False,\n",
        "        'recoded': False,\n",
        "    },\n",
        "    plot={'histogram': {'bayesian_blocks_bins': False}},\n",
        "    )\n",
        "\n",
        "profile_report.to_file(output_file=\"train.html\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTi09Ru40pO9",
        "colab_type": "text"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEoyD5YrunPC",
        "colab_type": "code",
        "outputId": "6ddea5d9-6976-4d72-f9e5-74396a1b2c35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "y = train['MIG_CAT']\n",
        "y.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "avg     0.397566\n",
              "low     0.359925\n",
              "high    0.242509\n",
              "Name: MIG_CAT, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwAFi8Zr1iBj",
        "colab_type": "text"
      },
      "source": [
        "Baseline prediction: majority class (avg) occurs with 40% frequency."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZY5Dnv2SrSQ",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgqQV5DtSskN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Arrange data into X features matrix and y target vector\n",
        "target = 'MIG_CAT'\n",
        "features = train.columns.drop([target, 'GEO_LABEL'])\n",
        "\n",
        "X_train = train[features]\n",
        "X_val = val[features]\n",
        "X_test = test[features]\n",
        "\n",
        "y_train = train[target]\n",
        "y_val = val[target]\n",
        "y_test = test[target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JwPZjEwTPXL",
        "colab_type": "code",
        "outputId": "bb73a92f-21f1-4d85-a5df-1d64fe58e904",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import category_encoders as ce\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.6217228464419475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnuJWxs2uicb",
        "colab_type": "text"
      },
      "source": [
        "## Feature Importances"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l57qMzzukph",
        "colab_type": "code",
        "outputId": "62696404-dc81-4824-8577-7629fc25e2a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        }
      },
      "source": [
        "# Get feature importances\n",
        "rf = pipeline.named_steps['randomforestclassifier']\n",
        "importances = pd.Series(rf.feature_importances_, X_train.columns)\n",
        "\n",
        "# Plot feature importances\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n = 12\n",
        "plt.figure(figsize=(10,n/2))\n",
        "plt.title(f'Top {n} features')\n",
        "importances.sort_values()[-n:].plot.barh(color='grey');"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAoQAAAF1CAYAAABxkftuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_6WYFTmut11",
        "colab_type": "text"
      },
      "source": [
        "## Drop-Column Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R56XzaQ9uzkG",
        "colab_type": "code",
        "outputId": "eca2d808-0008-4ee4-d4f3-cd9c96db66fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "column  = 'EUR_HAB_EU'\n",
        "\n",
        "# Fit without column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train.drop(columns=column), y_train)\n",
        "score_without = pipeline.score(X_val.drop(columns=column), y_val)\n",
        "print(f'Validation Accuracy without {column}: {score_without}')\n",
        "\n",
        "# Fit with column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train, y_train)\n",
        "score_with = pipeline.score(X_val, y_val)\n",
        "print(f'Validation Accuracy with {column}: {score_with}')\n",
        "\n",
        "# Compare the error with & without column\n",
        "print(f'Drop-Column Importance for {column}: {score_with - score_without}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy without EUR_HAB_EU: 0.5865168539325842\n",
            "Validation Accuracy with EUR_HAB_EU: 0.6217228464419475\n",
            "Drop-Column Importance for EUR_HAB_EU: 0.03520599250936329\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b1TWYipovATO",
        "colab_type": "code",
        "outputId": "700248cd-921d-4069-f736-b4f79160ee87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "column  = 'GEO'\n",
        "\n",
        "# Fit without column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train.drop(columns=column), y_train)\n",
        "score_without = pipeline.score(X_val.drop(columns=column), y_val)\n",
        "print(f'Validation Accuracy without {column}: {score_without}')\n",
        "\n",
        "# Compare the error with & without column\n",
        "print(f'Drop-Column Importance for {column}: {score_with - score_without}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy without GEO: 0.5797752808988764\n",
            "Drop-Column Importance for GEO: 0.04194756554307111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muVjlJlTvNC3",
        "colab_type": "code",
        "outputId": "14167552-0775-4d16-f1f9-cfe3e3cbb3eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "column  = 'PER_KM2'\n",
        "\n",
        "# Fit without column\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "pipeline.fit(X_train.drop(columns=column), y_train)\n",
        "score_without = pipeline.score(X_val.drop(columns=column), y_val)\n",
        "print(f'Validation Accuracy without {column}: {score_without}')\n",
        "\n",
        "# Compare the error with & without column\n",
        "print(f'Drop-Column Importance for {column}: {score_with - score_without}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy without PER_KM2: 0.6232209737827715\n",
            "Drop-Column Importance for PER_KM2: -0.001498127340823996\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ETf-syH7vUDL",
        "colab_type": "text"
      },
      "source": [
        "## Permutation Importance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ucfSHw_PJJ8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transformers = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median')\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hpSemTkFFP8i",
        "outputId": "044fa649-6bfa-4e39-8660-c3dec6c5f797",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "X_train_transformed = transformers.fit_transform(X_train)\n",
        "X_val_transformed = transformers.transform(X_val)\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "model.fit(X_train_transformed, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=-1, oob_score=False, random_state=42, verbose=0,\n",
              "                       warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCeRRyAWvtco",
        "colab_type": "code",
        "outputId": "8b7bc6c9-962d-42b8-c411-873bae772cbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "!pip install eli5"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting eli5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n",
            "\r\u001b[K     |███                             | 10kB 19.7MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 20kB 6.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 30kB 9.2MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 40kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 51kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 61kB 8.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 71kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 81kB 10.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 92kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 102kB 9.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 9.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.12.0)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.10.3)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.6)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.21.3)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.17.4)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (19.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.3.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (0.14.1)\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zfHiZZKJmqf",
        "colab_type": "code",
        "outputId": "be0f8ed3-0af7-4d47-c861-5baf35803ba6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "\n",
        "# 1. Calculate permutation importances\n",
        "permuter = PermutationImportance(\n",
        "    model, \n",
        "    scoring='accuracy', \n",
        "    n_iter=5, \n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "permuter.fit(X_val_transformed, y_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PermutationImportance(cv='prefit',\n",
              "                      estimator=RandomForestClassifier(bootstrap=True,\n",
              "                                                       class_weight=None,\n",
              "                                                       criterion='gini',\n",
              "                                                       max_depth=None,\n",
              "                                                       max_features='auto',\n",
              "                                                       max_leaf_nodes=None,\n",
              "                                                       min_impurity_decrease=0.0,\n",
              "                                                       min_impurity_split=None,\n",
              "                                                       min_samples_leaf=1,\n",
              "                                                       min_samples_split=2,\n",
              "                                                       min_weight_fraction_leaf=0.0,\n",
              "                                                       n_estimators=100,\n",
              "                                                       n_jobs=-1,\n",
              "                                                       oob_score=False,\n",
              "                                                       random_state=42,\n",
              "                                                       verbose=0,\n",
              "                                                       warm_start=False),\n",
              "                      n_iter=5, random_state=42, refit=True,\n",
              "                      scoring='accuracy')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peq3dVRzv5id",
        "colab_type": "code",
        "outputId": "5379c1bb-2f90-47c2-ab18-31d2d8f58016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "feature_names = X_val.columns.tolist()\n",
        "# pd.Series(permuter.feature_importances_, feature_names).sort_values()\n",
        "\n",
        "# 2. Display permutation importances\n",
        "eli5.show_weights(\n",
        "    permuter, \n",
        "    top=None, # show permutation importances for all features\n",
        "    feature_names=feature_names # must be a list\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0867\n",
              "                \n",
              "                    &plusmn; 0.0131\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                EUR_HAB_EU\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 87.11%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0463\n",
              "                \n",
              "                    &plusmn; 0.0077\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                GEO\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 87.32%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0452\n",
              "                \n",
              "                    &plusmn; 0.0077\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                EMP_PC\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 87.88%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0424\n",
              "                \n",
              "                    &plusmn; 0.0081\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                GDEATHRT\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 90.43%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0303\n",
              "                \n",
              "                    &plusmn; 0.0045\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                ED_LOW\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 91.48%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0256\n",
              "                \n",
              "                    &plusmn; 0.0078\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                AGEMOTH\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 91.66%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0249\n",
              "                \n",
              "                    &plusmn; 0.0122\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                ED_HIGH\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 92.78%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0202\n",
              "                \n",
              "                    &plusmn; 0.0138\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                PER_KM2\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 93.95%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0157\n",
              "                \n",
              "                    &plusmn; 0.0079\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                TOTFERRT\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 94.11%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0151\n",
              "                \n",
              "                    &plusmn; 0.0106\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                RT\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 95.53%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0102\n",
              "                \n",
              "                    &plusmn; 0.0105\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                GBIRTHRT\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                TIME\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5-ahM4PyRgT",
        "colab_type": "text"
      },
      "source": [
        "## Feature selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRGt5fTGyVCs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In this case just an elaborate way to drop 'TIME'.\n",
        "\n",
        "minimum_importance = 0\n",
        "mask = permuter.feature_importances_ > minimum_importance\n",
        "features = X_train.columns[mask]\n",
        "X_train = X_train[features]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sTTvB4PyY7k",
        "colab_type": "code",
        "outputId": "97c8ed9c-8598-4c35-c6c7-d8bcb81fa38a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_val = X_val[features]\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    SimpleImputer(strategy='median'), \n",
        "    RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "# Fit on train, score on val\n",
        "pipeline.fit(X_train, y_train)\n",
        "print('Validation Accuracy', pipeline.score(X_val, y_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.6374531835205992\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnzzYyXSyuxn",
        "colab_type": "code",
        "outputId": "0ee90c44-bd91-4147-9f5e-dcbc2058602f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "permuter.feature_importances_ - permuter.feature_importances_std_ > 0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        True,  True,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA2tT5jCwbKo",
        "colab_type": "text"
      },
      "source": [
        "## Gradient Boosting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M53ZRadiweWO",
        "colab_type": "code",
        "outputId": "588f23d5-75a0-42ee-a1f4-ebcfcb611586",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "from xgboost import XGBClassifier\n",
        "\n",
        "pipeline = make_pipeline(\n",
        "    ce.OrdinalEncoder(), \n",
        "    XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        ")\n",
        "\n",
        "pipeline.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('ordinalencoder',\n",
              "                 OrdinalEncoder(cols=['GEO'], drop_invariant=False,\n",
              "                                handle_missing='value', handle_unknown='value',\n",
              "                                mapping=[{'col': 'GEO', 'data_type': dtype('O'),\n",
              "                                          'mapping': AT        1\n",
              "AT1       2\n",
              "AT11      3\n",
              "AT12      4\n",
              "AT13      5\n",
              "       ... \n",
              "UKM8    442\n",
              "UKM9    443\n",
              "UKN     444\n",
              "UKN0    445\n",
              "NaN      -2\n",
              "Length: 446, dtype: int64}],\n",
              "                                return_df=True, verbose=0)),\n",
              "                ('xgbclassifier',\n",
              "                 XGBClassifier(base_score=0.5...oster='gbtree',\n",
              "                               colsample_bylevel=1, colsample_bynode=1,\n",
              "                               colsample_bytree=1, gamma=0, learning_rate=0.1,\n",
              "                               max_delta_step=0, max_depth=3,\n",
              "                               min_child_weight=1, missing=None,\n",
              "                               n_estimators=100, n_jobs=-1, nthread=None,\n",
              "                               objective='multi:softprob', random_state=42,\n",
              "                               reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
              "                               seed=None, silent=None, subsample=1,\n",
              "                               verbosity=1))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgsUR-Ljwj_D",
        "colab_type": "code",
        "outputId": "c27476f7-2473-4263-c115-63254640a774",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = pipeline.predict(X_val)\n",
        "print('Validation Accuracy', accuracy_score(y_val, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation Accuracy 0.5760299625468165\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5cs7RUqwpug",
        "colab_type": "code",
        "outputId": "8962018f-6250-44f2-dabe-392d98a17ccb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# fit_transfom on train, transform on val\n",
        "encoder = ce.OrdinalEncoder()\n",
        "X_train_encoded = encoder.fit_transform(X_train)\n",
        "X_val_encoded = encoder.transform(X_val)\n",
        "\n",
        "model = XGBClassifier(\n",
        "    n_estimators=1000,  # <= 1000 trees, depends on early stopping\n",
        "    max_depth=5,       # try deeper trees because of high cardinality categoricals\n",
        "    learning_rate=0.4,  # try higher learning rate\n",
        "    min_child_weight=0.5,  \n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "eval_set = [(X_train_encoded, y_train), \n",
        "            (X_val_encoded, y_val)]\n",
        "\n",
        "model.fit(X_train_encoded, y_train, \n",
        "          eval_set=eval_set,\n",
        "          eval_metric='merror', \n",
        "          early_stopping_rounds=50) # Stop if the score hasn't improved in 50 rounds"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\tvalidation_0-merror:0.290637\tvalidation_1-merror:0.448689\n",
            "Multiple eval metrics have been passed: 'validation_1-merror' will be used for early stopping.\n",
            "\n",
            "Will train until validation_1-merror hasn't improved in 50 rounds.\n",
            "[1]\tvalidation_0-merror:0.255243\tvalidation_1-merror:0.427715\n",
            "[2]\tvalidation_0-merror:0.244382\tvalidation_1-merror:0.433708\n",
            "[3]\tvalidation_0-merror:0.223034\tvalidation_1-merror:0.433708\n",
            "[4]\tvalidation_0-merror:0.208801\tvalidation_1-merror:0.418727\n",
            "[5]\tvalidation_0-merror:0.210487\tvalidation_1-merror:0.405993\n",
            "[6]\tvalidation_0-merror:0.202622\tvalidation_1-merror:0.4\n",
            "[7]\tvalidation_0-merror:0.189888\tvalidation_1-merror:0.400749\n",
            "[8]\tvalidation_0-merror:0.183521\tvalidation_1-merror:0.411985\n",
            "[9]\tvalidation_0-merror:0.178464\tvalidation_1-merror:0.411985\n",
            "[10]\tvalidation_0-merror:0.167978\tvalidation_1-merror:0.416479\n",
            "[11]\tvalidation_0-merror:0.165918\tvalidation_1-merror:0.414232\n",
            "[12]\tvalidation_0-merror:0.161798\tvalidation_1-merror:0.408989\n",
            "[13]\tvalidation_0-merror:0.156929\tvalidation_1-merror:0.408989\n",
            "[14]\tvalidation_0-merror:0.149625\tvalidation_1-merror:0.407491\n",
            "[15]\tvalidation_0-merror:0.144757\tvalidation_1-merror:0.405993\n",
            "[16]\tvalidation_0-merror:0.141573\tvalidation_1-merror:0.405993\n",
            "[17]\tvalidation_0-merror:0.137453\tvalidation_1-merror:0.403745\n",
            "[18]\tvalidation_0-merror:0.132397\tvalidation_1-merror:0.4\n",
            "[19]\tvalidation_0-merror:0.129401\tvalidation_1-merror:0.400749\n",
            "[20]\tvalidation_0-merror:0.124157\tvalidation_1-merror:0.399251\n",
            "[21]\tvalidation_0-merror:0.120974\tvalidation_1-merror:0.394757\n",
            "[22]\tvalidation_0-merror:0.114419\tvalidation_1-merror:0.394008\n",
            "[23]\tvalidation_0-merror:0.112734\tvalidation_1-merror:0.39176\n",
            "[24]\tvalidation_0-merror:0.111049\tvalidation_1-merror:0.388764\n",
            "[25]\tvalidation_0-merror:0.107865\tvalidation_1-merror:0.391011\n",
            "[26]\tvalidation_0-merror:0.103184\tvalidation_1-merror:0.398502\n",
            "[27]\tvalidation_0-merror:0.100187\tvalidation_1-merror:0.396255\n",
            "[28]\tvalidation_0-merror:0.096816\tvalidation_1-merror:0.392509\n",
            "[29]\tvalidation_0-merror:0.09176\tvalidation_1-merror:0.385768\n",
            "[30]\tvalidation_0-merror:0.08764\tvalidation_1-merror:0.382772\n",
            "[31]\tvalidation_0-merror:0.085019\tvalidation_1-merror:0.382022\n",
            "[32]\tvalidation_0-merror:0.082772\tvalidation_1-merror:0.376779\n",
            "[33]\tvalidation_0-merror:0.079588\tvalidation_1-merror:0.381273\n",
            "[34]\tvalidation_0-merror:0.076217\tvalidation_1-merror:0.378277\n",
            "[35]\tvalidation_0-merror:0.070974\tvalidation_1-merror:0.376779\n",
            "[36]\tvalidation_0-merror:0.067228\tvalidation_1-merror:0.373783\n",
            "[37]\tvalidation_0-merror:0.066479\tvalidation_1-merror:0.379026\n",
            "[38]\tvalidation_0-merror:0.063109\tvalidation_1-merror:0.377528\n",
            "[39]\tvalidation_0-merror:0.06161\tvalidation_1-merror:0.379026\n",
            "[40]\tvalidation_0-merror:0.060112\tvalidation_1-merror:0.37603\n",
            "[41]\tvalidation_0-merror:0.059925\tvalidation_1-merror:0.378277\n",
            "[42]\tvalidation_0-merror:0.056742\tvalidation_1-merror:0.376779\n",
            "[43]\tvalidation_0-merror:0.055243\tvalidation_1-merror:0.373783\n",
            "[44]\tvalidation_0-merror:0.054869\tvalidation_1-merror:0.371536\n",
            "[45]\tvalidation_0-merror:0.051498\tvalidation_1-merror:0.370037\n",
            "[46]\tvalidation_0-merror:0.049438\tvalidation_1-merror:0.368539\n",
            "[47]\tvalidation_0-merror:0.04588\tvalidation_1-merror:0.370787\n",
            "[48]\tvalidation_0-merror:0.045318\tvalidation_1-merror:0.371536\n",
            "[49]\tvalidation_0-merror:0.042135\tvalidation_1-merror:0.368539\n",
            "[50]\tvalidation_0-merror:0.041011\tvalidation_1-merror:0.367041\n",
            "[51]\tvalidation_0-merror:0.040262\tvalidation_1-merror:0.365543\n",
            "[52]\tvalidation_0-merror:0.039888\tvalidation_1-merror:0.365543\n",
            "[53]\tvalidation_0-merror:0.038951\tvalidation_1-merror:0.367041\n",
            "[54]\tvalidation_0-merror:0.037828\tvalidation_1-merror:0.367041\n",
            "[55]\tvalidation_0-merror:0.038015\tvalidation_1-merror:0.367041\n",
            "[56]\tvalidation_0-merror:0.037266\tvalidation_1-merror:0.363296\n",
            "[57]\tvalidation_0-merror:0.035768\tvalidation_1-merror:0.365543\n",
            "[58]\tvalidation_0-merror:0.034831\tvalidation_1-merror:0.362547\n",
            "[59]\tvalidation_0-merror:0.033333\tvalidation_1-merror:0.359551\n",
            "[60]\tvalidation_0-merror:0.031835\tvalidation_1-merror:0.358052\n",
            "[61]\tvalidation_0-merror:0.031086\tvalidation_1-merror:0.356554\n",
            "[62]\tvalidation_0-merror:0.031273\tvalidation_1-merror:0.362547\n",
            "[63]\tvalidation_0-merror:0.027528\tvalidation_1-merror:0.3603\n",
            "[64]\tvalidation_0-merror:0.024906\tvalidation_1-merror:0.359551\n",
            "[65]\tvalidation_0-merror:0.025281\tvalidation_1-merror:0.361798\n",
            "[66]\tvalidation_0-merror:0.024719\tvalidation_1-merror:0.362547\n",
            "[67]\tvalidation_0-merror:0.024532\tvalidation_1-merror:0.363296\n",
            "[68]\tvalidation_0-merror:0.023034\tvalidation_1-merror:0.366292\n",
            "[69]\tvalidation_0-merror:0.022846\tvalidation_1-merror:0.368539\n",
            "[70]\tvalidation_0-merror:0.022097\tvalidation_1-merror:0.367041\n",
            "[71]\tvalidation_0-merror:0.020225\tvalidation_1-merror:0.367041\n",
            "[72]\tvalidation_0-merror:0.01985\tvalidation_1-merror:0.364794\n",
            "[73]\tvalidation_0-merror:0.019476\tvalidation_1-merror:0.362547\n",
            "[74]\tvalidation_0-merror:0.01985\tvalidation_1-merror:0.358052\n",
            "[75]\tvalidation_0-merror:0.019288\tvalidation_1-merror:0.357303\n",
            "[76]\tvalidation_0-merror:0.018727\tvalidation_1-merror:0.355805\n",
            "[77]\tvalidation_0-merror:0.01779\tvalidation_1-merror:0.356554\n",
            "[78]\tvalidation_0-merror:0.016667\tvalidation_1-merror:0.352809\n",
            "[79]\tvalidation_0-merror:0.015543\tvalidation_1-merror:0.354307\n",
            "[80]\tvalidation_0-merror:0.015356\tvalidation_1-merror:0.353558\n",
            "[81]\tvalidation_0-merror:0.015169\tvalidation_1-merror:0.352809\n",
            "[82]\tvalidation_0-merror:0.014981\tvalidation_1-merror:0.355056\n",
            "[83]\tvalidation_0-merror:0.014232\tvalidation_1-merror:0.358052\n",
            "[84]\tvalidation_0-merror:0.014045\tvalidation_1-merror:0.357303\n",
            "[85]\tvalidation_0-merror:0.01367\tvalidation_1-merror:0.354307\n",
            "[86]\tvalidation_0-merror:0.011798\tvalidation_1-merror:0.355805\n",
            "[87]\tvalidation_0-merror:0.010861\tvalidation_1-merror:0.353558\n",
            "[88]\tvalidation_0-merror:0.0103\tvalidation_1-merror:0.352809\n",
            "[89]\tvalidation_0-merror:0.009925\tvalidation_1-merror:0.352809\n",
            "[90]\tvalidation_0-merror:0.008989\tvalidation_1-merror:0.356554\n",
            "[91]\tvalidation_0-merror:0.008989\tvalidation_1-merror:0.355805\n",
            "[92]\tvalidation_0-merror:0.009176\tvalidation_1-merror:0.357303\n",
            "[93]\tvalidation_0-merror:0.009176\tvalidation_1-merror:0.355805\n",
            "[94]\tvalidation_0-merror:0.008614\tvalidation_1-merror:0.355805\n",
            "[95]\tvalidation_0-merror:0.008427\tvalidation_1-merror:0.35206\n",
            "[96]\tvalidation_0-merror:0.007865\tvalidation_1-merror:0.35206\n",
            "[97]\tvalidation_0-merror:0.006554\tvalidation_1-merror:0.352809\n",
            "[98]\tvalidation_0-merror:0.006367\tvalidation_1-merror:0.35206\n",
            "[99]\tvalidation_0-merror:0.005618\tvalidation_1-merror:0.355056\n",
            "[100]\tvalidation_0-merror:0.005993\tvalidation_1-merror:0.355805\n",
            "[101]\tvalidation_0-merror:0.005805\tvalidation_1-merror:0.355805\n",
            "[102]\tvalidation_0-merror:0.005431\tvalidation_1-merror:0.357303\n",
            "[103]\tvalidation_0-merror:0.005056\tvalidation_1-merror:0.355805\n",
            "[104]\tvalidation_0-merror:0.004682\tvalidation_1-merror:0.354307\n",
            "[105]\tvalidation_0-merror:0.004494\tvalidation_1-merror:0.356554\n",
            "[106]\tvalidation_0-merror:0.004869\tvalidation_1-merror:0.354307\n",
            "[107]\tvalidation_0-merror:0.004682\tvalidation_1-merror:0.355056\n",
            "[108]\tvalidation_0-merror:0.004682\tvalidation_1-merror:0.356554\n",
            "[109]\tvalidation_0-merror:0.004494\tvalidation_1-merror:0.355056\n",
            "[110]\tvalidation_0-merror:0.00412\tvalidation_1-merror:0.355056\n",
            "[111]\tvalidation_0-merror:0.00412\tvalidation_1-merror:0.355805\n",
            "[112]\tvalidation_0-merror:0.003558\tvalidation_1-merror:0.355805\n",
            "[113]\tvalidation_0-merror:0.003184\tvalidation_1-merror:0.359551\n",
            "[114]\tvalidation_0-merror:0.003184\tvalidation_1-merror:0.359551\n",
            "[115]\tvalidation_0-merror:0.002996\tvalidation_1-merror:0.361049\n",
            "[116]\tvalidation_0-merror:0.002247\tvalidation_1-merror:0.358052\n",
            "[117]\tvalidation_0-merror:0.001873\tvalidation_1-merror:0.359551\n",
            "[118]\tvalidation_0-merror:0.00206\tvalidation_1-merror:0.358801\n",
            "[119]\tvalidation_0-merror:0.001873\tvalidation_1-merror:0.356554\n",
            "[120]\tvalidation_0-merror:0.001873\tvalidation_1-merror:0.358801\n",
            "[121]\tvalidation_0-merror:0.001873\tvalidation_1-merror:0.358801\n",
            "[122]\tvalidation_0-merror:0.001685\tvalidation_1-merror:0.357303\n",
            "[123]\tvalidation_0-merror:0.001873\tvalidation_1-merror:0.359551\n",
            "[124]\tvalidation_0-merror:0.001685\tvalidation_1-merror:0.358052\n",
            "[125]\tvalidation_0-merror:0.001685\tvalidation_1-merror:0.358052\n",
            "[126]\tvalidation_0-merror:0.001311\tvalidation_1-merror:0.362547\n",
            "[127]\tvalidation_0-merror:0.001311\tvalidation_1-merror:0.361049\n",
            "[128]\tvalidation_0-merror:0.000936\tvalidation_1-merror:0.357303\n",
            "[129]\tvalidation_0-merror:0.000936\tvalidation_1-merror:0.355805\n",
            "[130]\tvalidation_0-merror:0.000936\tvalidation_1-merror:0.356554\n",
            "[131]\tvalidation_0-merror:0.000936\tvalidation_1-merror:0.356554\n",
            "[132]\tvalidation_0-merror:0.000936\tvalidation_1-merror:0.354307\n",
            "[133]\tvalidation_0-merror:0.000749\tvalidation_1-merror:0.356554\n",
            "[134]\tvalidation_0-merror:0.000749\tvalidation_1-merror:0.355805\n",
            "[135]\tvalidation_0-merror:0.000749\tvalidation_1-merror:0.357303\n",
            "[136]\tvalidation_0-merror:0.000749\tvalidation_1-merror:0.355805\n",
            "[137]\tvalidation_0-merror:0.000749\tvalidation_1-merror:0.354307\n",
            "[138]\tvalidation_0-merror:0.000749\tvalidation_1-merror:0.355056\n",
            "[139]\tvalidation_0-merror:0.000562\tvalidation_1-merror:0.354307\n",
            "[140]\tvalidation_0-merror:0.000562\tvalidation_1-merror:0.352809\n",
            "[141]\tvalidation_0-merror:0.000375\tvalidation_1-merror:0.356554\n",
            "[142]\tvalidation_0-merror:0.000187\tvalidation_1-merror:0.358052\n",
            "[143]\tvalidation_0-merror:0.000187\tvalidation_1-merror:0.355056\n",
            "[144]\tvalidation_0-merror:0.000187\tvalidation_1-merror:0.355805\n",
            "[145]\tvalidation_0-merror:0.000187\tvalidation_1-merror:0.355056\n",
            "Stopping. Best iteration:\n",
            "[95]\tvalidation_0-merror:0.008427\tvalidation_1-merror:0.35206\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
              "              learning_rate=0.4, max_delta_step=0, max_depth=5,\n",
              "              min_child_weight=0.5, missing=None, n_estimators=1000, n_jobs=-1,\n",
              "              nthread=None, objective='multi:softprob', random_state=0,\n",
              "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "              silent=None, subsample=1, verbosity=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESaAI8ZrxswQ",
        "colab_type": "code",
        "outputId": "241f2d95-4f99-4e21-dd79-1aa85367d918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        }
      },
      "source": [
        "results = model.evals_result()\n",
        "train_error = results['validation_0']['merror']\n",
        "val_error = results['validation_1']['merror']\n",
        "epoch = range(1, len(train_error)+1)\n",
        "plt.plot(epoch, train_error, label='Train')\n",
        "plt.plot(epoch, val_error, label='Validation')\n",
        "plt.ylabel('Classification Error')\n",
        "plt.xlabel('Model Complexity (n_estimators)')\n",
        "# plt.ylim((0.35, 0.4)) # Zoom in\n",
        "plt.legend();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEHCAYAAACjh0HiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}